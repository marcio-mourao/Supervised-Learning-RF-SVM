{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f77e2465-07f3-4ad0-ab0b-970cc19da161"
    }
   },
   "source": [
    "# <center> Supervised Machine Learning <br/> Random Forests and Support Vector Machines (SVMs) <br/><br/> CSCAR WORKSHOP - Data Science Skills Series <br/><br/> 04/19/2017\n",
    "## <center> Marcio Mourao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Setup for Anaconda / Jupyter Notebook\n",
    "\n",
    "<ul>\n",
    "    <li>Go to the page https://marcio-mourao.github.io/</li>\n",
    "    <li>Download the materials under \"Supervised Machine Learning in Python using Scikit-Learn (Random Forests and SVMs)\" to your \"username/Documents\"</li><br/>\n",
    "    \n",
    "    <li>Click the Windows button (Bottom Left Corner)</li>\n",
    "    <li>Click \"All apps\"</li>\n",
    "    <li>Click \"Anaconda3 (64-bit)\"</li>\n",
    "    <li>Click \"Anaconda Prompt\" </li>\n",
    "    <li>Enter \"conda update scikit-learn\"</li><br/>\n",
    "    \n",
    "    <li>Click the Windows button (Bottom Left Corner)</li>\n",
    "    <li>Click \"All apps\"</li>\n",
    "    <li>Click \"Anaconda3 (64-bit)\"</li>\n",
    "    <li>Click \"Jupyter Notebook\" </li><br/>\n",
    "    \n",
    "    <li>Click \"Workshop.ipynb\" (this should open a new tab in the browser)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction\n",
    "\n",
    "<ul>\n",
    "  <li>Please, sign up the sheet! </li>\n",
    "  <li>Don't forget to go to: http://cscar.research.umich.edu/ to know what we're offering!</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Summary of this workshop\n",
    "\n",
    "<ul>\n",
    "  <li>Random Forests (use the 1994 census dataset)</li>\n",
    "  <ul>\n",
    "     <li>Brief description of the dataset</li>\n",
    "     <li>Load and describe the data (using Pandas dataframes)</li>\n",
    "     <li>Machine Learning</li>\n",
    "  </ul><br>\n",
    "  <li>SVM (use handwritten digits dataset) </li>\n",
    "  <ul>\n",
    "     <li>Brief description of the dataset</li>\n",
    "     <li>Load and describe the data (using numpy)</li>\n",
    "     <li>Machine Learning</li>\n",
    "  </ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> References\n",
    "\n",
    "<ul>\n",
    "  <li>https://www.continuum.io/anaconda-overview</li>\n",
    "  <li>http://www.numpy.org/</li>\n",
    "  <li>http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html</li>\n",
    "  <li>http://matplotlib.org/</li>\n",
    "  <li>http://pandas.pydata.org/pandas-docs/stable/10min.html</li>\n",
    "  <li>http://scikit-learn.org/stable/</li>\n",
    "  <li>http://statsmodels.sourceforge.net/</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check Python version\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant general modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some info about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). \n",
    "\n",
    "<b>The prediction task is to determine whether a person makes over $50K a year!</b>\n",
    "\n",
    "<b>Attributes:</b>\n",
    "\n",
    "income: >50K, <=50K\n",
    "\n",
    "age: continuous\n",
    "\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\n",
    "\n",
    "fnlwgt: continuous\n",
    "\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool\n",
    "\n",
    "education-num: continuous\n",
    "\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse\n",
    "\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces\n",
    "\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n",
    "\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n",
    "\n",
    "sex: Female, Male\n",
    "\n",
    "capital-gain: continuous\n",
    "\n",
    "capital-loss: continuous\n",
    "\n",
    "hours-per-week: continuous\n",
    "\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1862e15b-a819-4062-93a3-b68d3f0a0865"
    }
   },
   "outputs": [],
   "source": [
    "#Creates a dataframe named \"adults\" from reading the file \"adult.csv\"\n",
    "adults = pd.read_csv('adult.csv',na_values=['?'])\n",
    "adults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Displays number of lines and number of columns of the dataframe\n",
    "adults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Displays the data types associated with each dataframe column\n",
    "adults.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Describes everything in the dataframe\n",
    "adults.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "61b8eb03-4209-4149-bd6d-dd930fd1bde1"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Displays whether columns contain any null values\n",
    "adults.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Count the number of missing values in each column of the dataframe\n",
    "adults.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Count the number of missing values in each column of the dataframe and sums them up\n",
    "adults.apply(lambda x: sum(x.isnull()),axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Count number of lines with NaNs\n",
    "adults.apply(lambda x: x.isnull().any(),axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fraction of observations with NaNs (potentially for removal)\n",
    "2399/adults.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Removes any lines from the dataframe that contains NaNs \n",
    "#(be careful about what you decide to do with missing values)\n",
    "adults=adults.dropna(axis=0,how='any')\n",
    "adults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Displays number of lines and number of columns of the dataframe\n",
    "adults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c128b972-06c0-423d-a7b0-3faf2a3879c0"
    }
   },
   "outputs": [],
   "source": [
    "#Displays the first rows of the dataframe\n",
    "adults.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates a label encoder object\n",
    "le=LabelEncoder()\n",
    "\n",
    "#Creates a copy of the dataframe\n",
    "adults2=adults.copy()\n",
    "\n",
    "#Converts category \n",
    "for col in adults.select_dtypes(include=['object']).columns.values:\n",
    "    col_slice = adults2[col]\n",
    "    adults2[col + '_enc']=le.fit(col_slice.values).transform(col_slice.values)\n",
    "\n",
    "adults2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check new data types\n",
    "adults2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define covariates in X and dependent variable in y\n",
    "X = adults2[['age','workclass_enc','education.num','marital.status_enc','occupation_enc',\n",
    "            'race_enc','sex_enc','relationship_enc','capital.gain','capital.loss',\n",
    "            'hours.per.week','native.country_enc']]\n",
    "y = adults2.income_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtain the data for the fitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)\n",
    "\n",
    "print('Total number of records: ', adults2.shape[0])\n",
    "print('Type of X_train: ', type(X_train))\n",
    "print('Number of records in X_train: ', len(X_train))\n",
    "print('Fraction on X_train: ', len(X_train)/adults2.shape[0])\n",
    "print('Number of records in y_train: ', len(y_train))\n",
    "print('Type of y_train: \\n\\n', type(y_train))\n",
    "\n",
    "print('Type of X_test: ', type(X_test))\n",
    "print('Number of records in X_test: ', len(X_test))\n",
    "print('Fraction on X_test: ', len(X_test)/adults2.shape[0])\n",
    "print('Number of records in y_test: ', len(y_test))\n",
    "print('Type of y_test: ', type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates a RF classification model\n",
    "RF_model = RandomForestClassifier(n_estimators=10, criterion='gini')\n",
    "\n",
    "#Fit to the data\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtain class predictions\n",
    "y_pred_RF_prob = RF_model.predict_proba(X_test)\n",
    "print('Predicted probabilities: \\n', y_pred_RF_prob)\n",
    "\n",
    "#Obtain probability predictions\n",
    "y_pred_RF_class = RF_model.predict(X_test)\n",
    "print('Predicted classes: \\n', y_pred_RF_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtains accuracy score\n",
    "print('RF Score: ', metrics.accuracy_score(y_test, y_pred_RF_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtains confusion matrix\n",
    "RF_cm=metrics.confusion_matrix(y_test,y_pred_RF_class)\n",
    "RF_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Capture feature importance from the RF model\n",
    "feature_imp=RF_model.feature_importances_\n",
    "\n",
    "#Create plot of feature importance\n",
    "positions = np.arange(12)\n",
    "plt.barh(positions, feature_imp, align='center')\n",
    "plt.xlabel(\"Feature Importances\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.yticks(positions, ('Age','Working Class', 'Years Education', 'Marital Status', 'Occupation',\n",
    "                       'Race', 'Sex', 'Relationship Status', 'Capital Gain', 'Capital Loss',\n",
    "                       'Hours per Week','Native Country'))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KFolds and Cross_val_scores\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "print('Cross validation score: ', cross_val_score(RF_model, X, y, cv=kf).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some info about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The handwritten digits dataset is made up of 1797 8x8 images \n",
    "\n",
    "Each image, like the one shown below, is of a hand-written digit\n",
    "\n",
    "<b>The goal is to recognize handwritten digits</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "from sklearn import datasets\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(digits.data)\n",
    "print(digits.data.shape)\n",
    "print(digits.images)\n",
    "print(digits.images.shape)\n",
    "print(digits.target)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#As an example, displays a digit\n",
    "print(digits.data[-2])\n",
    "plt.imshow(digits.images[-2], cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create predictors and target sets\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "#Obtain the data for the fitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.85, random_state=13)\n",
    "\n",
    "print('Total number of records: ', digits.data.shape[0])\n",
    "print('Type of X_train: ', type(X_train))\n",
    "print('Number of records in X_train: ', len(X_train))\n",
    "print('Fraction on X_train: ', len(X_train)/digits.data.shape[0])\n",
    "print('Number of records in y_train: ', len(y_train))\n",
    "print('Type of y_train: \\n\\n', type(y_train))\n",
    "\n",
    "print('Type of X_test: ', type(X_test))\n",
    "print('Number of records in X_test: ', len(X_test))\n",
    "print('Fraction on X_test: ', len(X_test)/digits.data.shape[0])\n",
    "print('Number of records in y_test: ', len(y_test))\n",
    "print('Type of y_test: ', type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates the object\n",
    "SVM_model = svm.SVC(gamma=0.001, C=100, probability= True)\n",
    "\n",
    "#Fit to the data\n",
    "SVM_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtain probability predictions\n",
    "y_pred_SVM_prob = SVM_model.predict_proba(X_test)\n",
    "print('Predicted probabilities: \\n', y_pred_SVM_prob)\n",
    "\n",
    "#Obtain class predictions\n",
    "y_pred_SVM_class = SVM_model.predict(X_test)\n",
    "print('Predicted classes: \\n', y_pred_SVM_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtains accuracy score\n",
    "print('SVM Score: ', metrics.accuracy_score(y_test, y_pred_SVM_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtains confusion matrix\n",
    "SVM_cm=metrics.confusion_matrix(y_test,y_pred_SVM_class)\n",
    "SVM_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtain optimal SVM for both parameters C and Gamma\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C_range = np.logspace(-2, 2, 2)\n",
    "gamma_range = np.logspace(-3, 3, 2)\n",
    "param_grid = dict(C=C_range,gamma=gamma_range)\n",
    "cv = KFold(n_splits=5, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\" % (grid.best_params_, grid.best_score_))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nbpresent": {
   "slides": {
    "8ce21dab-2b7a-439c-8f0a-8a1036a1ac0d": {
     "id": "8ce21dab-2b7a-439c-8f0a-8a1036a1ac0d",
     "prev": null,
     "regions": {
      "d8401624-efe9-4853-a676-de863b4ba3cd": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "d8401624-efe9-4853-a676-de863b4ba3cd"
      }
     },
     "theme": null
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
